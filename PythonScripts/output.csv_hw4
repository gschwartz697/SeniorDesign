Hello! I am getting an error accessing the specific columns of the table using get- I am using JSoup. I was wondering if anyone knows why that might be. I have looked online but not found an answer.,I am having a hard time finding the online java source for Part 2. Where should i be looking for it?
"I've been attempting HW4 by adding several of an author's books to the corpus, then comparing each of the documents together. However, the calculated cosine similarities are VERY low (&lt;0.05), which I thought didn't make any sense. I then realized that, if there are a lot of words that appear in ALL the documents, each of them will be represented by a ""0"" in the Weight vector of each document (since the IDF of that term will be 0). How do we account for this in determining how similar documents actually are?","Do we need to normalize our tf values? (i.e. instead of just using the frequency of the term in for a specific document, using the frequency of the term divided by the total number of words in the document). I did not normalize and the IR book (https://nlp.stanford.edu/IR-book/pdf/06vect.pdf) doesn't, but I just wanted to check that this was okay."
"I know the programming part of the HW must be submitted tonight to meet the deadline, but since the original writeup said we could submit the theory section in class if we wanted, would it be acceptable to bring a hardcopy of that section at the start of class tomorrow? ","Extra Credit is listed twice - once in part 1, and once again in part 2. Is this supposed to mean that we are supposed to implement in code something like the theoretical results for part 1 in code form toward part 2 (10 points + 10 points = 20 points total), or should we just do the written section (10 points)? "
"What does this instruction imply: ""ignore the rest of the terms in all the documents""? Does it mean, for example, document B would be ""Dobby elf"" instead since we're ignoring other words in the document?",Is it alright if for 4 c) in theory we consider all words in the document and take the tf as a faction of all the words? Or must we ignore every other word other than the words in question? 
"Let's say we have a document that only contains one phrase.

When comparing that document to other documents that also contain that phrase, won't cosine similarity favor the documents that have the phrase only once (as opposed to a document that may have the phrase several times). This seems counterintuitive to me, because more frequency should mean more similarity. Or am I not doing my calculation correctly?","My impression is that cos similarity is supposed to be higher when 2 documents are similar. However, when I use nearly identical documents in the simulator(I'm talking 1 just omits a few words compared to the other) I get that it equals 0.0. Am I doing something wrong?"
"Whenever I import the contents into a project, I get a ton of compilation errors because eclipse thinks the Document class is from Jsoup not from Ir.","Whenever I import the contents into a project, I get a ton of compilation errors because eclipse thinks the Document class is from Jsoup not from Ir."
"I collected a bunch of news articles for a class last year (Introduction to Linguistics), and manually converted them all to .txt files. I think they would be nice to use as data for part 2. Is this OK?","Hi,Sorry, but I was looking through my prakharb folder for my HW4 submission and I realized I only zipped one of the files - I've attached the correct zip file here - let me know if I should resubmit to Canvas!- Prakhar Bhandariprakharb.zip"
